# -*- coding: utf-8 -*-
"""518 Capestone  final .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jLdgXC_Dq-FezeoNXXFjmKmmJTIbayG-
"""

# send http requests to get HTTP response object
import requests
# BeautifulSoup to pull HTML data from a HTTP response object
from bs4 import BeautifulSoup
# parser: converting JSON data into other format
import lxml

# target page
webpage = 'https://j2cweb-backend-prod.jobs2careers.com/api/v1/jobAdsWithKQ/result'

# send http requests, and get the http response
responses = requests.get(webpage)

# what is the status code?
responses.status_code

# get the text portion of response, HTML source code for the page
contents = responses.text

contents

# parse the text content using beautifulsoup to get HTML code
soup = BeautifulSoup(contents,'lxml')

# real HTML code for the page, you can display it using online editor
soup

# prettify() just make HTML code prettier
print(soup.prettify())

import requests

# API URL and parameters
url = "https://j2cweb-backend-prod.jobs2careers.com/api/v1/jobAdsWithKQ/result"
params = {
    "q": "software engineer",
    "l": "New York, NY",
    "sort": "r",
    "start": 60,
    "limit": 10,
}

# Fetch data from API
response = requests.get(url, params=params)
if response.status_code == 200:
    data = response.json()
    job_ads = data.get("jobAds", {})

    # Extract relevant data and print it
    for job_id, job_details in job_ads.items():
        # Extract salary details, handling cases where it's missing
        salary_details = job_details.get("salaryDetails", {})

        # Check if salary_details is not empty before processing
        if salary_details:
            salaries = []
            units = []
            labels = []
            for _, salary in salary_details.items():
                salaries.append(salary.get("value"))
                units.append(salary.get("unit"))
                labels.append(salary.get("label"))

            print(f"Salaries: {', '.join(map(str, salaries))}")  # Combine salary values
            print(f"Units: {', '.join(units)}")                  # Combine units
            print(f"Labels: {', '.join(labels)}")                # Combine labels
        else:
            print("Salaries: Not available") # indicate if the salary information is missing


        # Print other job details
        print(f"Job ID: {job_id}")
        print(f"Title: {job_details.get('title')}")
        print(f"Company: {job_details.get('companyName')}")
        print(f"Location: {job_details.get('cityState')}")
        print(f"Date Posted: {job_details.get('datePosted')}")
        print(f"Link: {job_details.get('link')}")
        print(f"Description: {job_details.get('description')}")

        print("-" * 50)  # Divider between jobs
else:
    print(f"Failed to fetch data. Status code: {response.status_code}")

import pandas as pd



# Convert the list of dictionaries to a DataFrame
df = pd.DataFrame(job_data)

# Save the DataFrame to an Excel file
excel_file = "jobs_data__.xlsx"
df.to_excel(excel_file, index=False)

print(f"Data saved to {excel_file}")

import matplotlib.pyplot as plt
import seaborn as sns

#  Bar chart of top 10 job titles
top_titles = df['Title'].value_counts().head(10)
plt.figure(figsize=(10, 6))
sns.barplot(x=top_titles.index, y=top_titles.values)
plt.title('Top 10 Job Titles')
plt.xlabel('Job Title')
plt.ylabel('Frequency')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for readability
plt.show()

#  Location Distribution
location_counts = df['Location'].value_counts()
plt.figure(figsize=(10, 6))
sns.barplot(x=location_counts.index, y=location_counts.values)
plt.title('Job Location Distribution')
plt.xlabel('Location')
plt.ylabel('Frequency')
plt.xticks(rotation=45, ha='right')
plt.show()

#  Top Hiring Companies
company_counts = df['Company'].value_counts().head(10)  # Top 10
plt.figure(figsize=(10, 6))
sns.barplot(x=company_counts.index, y=company_counts.values)
plt.title('Top 10 Hiring Companies')
plt.xlabel('Company')
plt.ylabel('Number of Job Postings')
plt.xticks(rotation=45, ha='right')
plt.show()

#  Job Posting Trend (assuming 'Date Posted' is a datetime column)
df['Date Posted'] = pd.to_datetime(df['Date Posted'])
postings_by_day = df.groupby(df['Date Posted'].dt.date)['Job ID'].count()
plt.figure(figsize=(12, 6))
postings_by_day.plot()
plt.title('Job Posting Trend Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Job Postings')
plt.show()